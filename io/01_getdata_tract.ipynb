{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b52326",
   "metadata": {},
   "source": "# Tile Rubin tract 5063 + fetch Euclid counterparts (quota-friendly)\n\nDownloads row-by-row: for each row of patches, tiles all Rubin data first,\nthen fetches Euclid counterparts, plots progress, archives the row into a\n`.tar.gz`, and pauses so you can download and delete before continuing.\n\nProgress is tracked in `tile_progress.log` for safe resume.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334eb31c",
   "metadata": {},
   "outputs": [],
   "source": "import os, glob, io, tarfile\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom lsst.daf.butler import Butler\nimport lsst.geom as geom\nimport lsst.afw.geom as afwGeom\nfrom lsst.daf.base import PropertySet\nfrom astroquery.ipac.irsa import Irsa\nfrom astropy.coordinates import SkyCoord\nfrom astropy import units as u\nfrom astropy.table import Table\nfrom astropy.io import fits\nfrom astropy.nddata import Cutout2D\nfrom astropy.wcs import WCS\nimport fsspec\n\n# ---- Config ----\nTRACT = 5063\nSKYMAP = \"lsst_cells_v1\"\nREPO = \"dp1\"\nCOLLECTION = \"LSSTComCam/DP1\"\nDATASETTYPE = \"deep_coadd\"\n\nOUT_RUBIN_ROOT = \"../data/rubin_tiles_tract5063\"\nOUT_EUCLID_DIR = \"../data/euclid_tiles_tract5063\"\nARCHIVE_DIR = \"../data/tile_archives\"\nPROGRESS_FILE = \"../data/tile_progress.log\"\nDATA_ROOT = os.path.abspath(\"../data\")\n\nfor d in [OUT_RUBIN_ROOT, OUT_EUCLID_DIR, ARCHIVE_DIR]:\n    os.makedirs(d, exist_ok=True)\n\nbands_rubin = (\"u\", \"g\", \"r\", \"i\", \"z\", \"y\")\nbands_euclid = (\"VIS\", \"Y\", \"J\", \"H\")\nTILE_SIZE = 512\nSTRIDE = 256\nEUCLID_SIZE_ARCSEC = 105.0\nROW_BATCH = 5   # patches per batch if row grouping fails\n\nbutler = Butler(REPO, collections=COLLECTION)\n\n\n# ---- Rubin helpers ----\n\ndef get_patches_in_tract(butler, tract, band=\"r\"):\n    refs = butler.query_datasets(\n        DATASETTYPE,\n        where=\"tract = tract AND band = band AND skymap = skymap\",\n        bind={\"tract\": tract, \"band\": band, \"skymap\": SKYMAP},\n        with_dimension_records=True,\n    )\n    return sorted({ref.dataId[\"patch\"] for ref in refs})\n\n\ndef load_patch_exposures(butler, tract, patch, bands=bands_rubin):\n    exps = {}\n    available = []\n    for b in bands:\n        dataId = {\"tract\": tract, \"patch\": patch, \"band\": b, \"skymap\": SKYMAP}\n        try:\n            exps[b] = butler.get(DATASETTYPE, dataId=dataId)\n            available.append(b)\n        except Exception as e:\n            print(f\"    skipping band {b} for patch {patch}: {e}\")\n    if not available:\n        raise RuntimeError(f\"No bands found for patch {patch}\")\n    return exps, exps[available[0]].getWcs(), tuple(available)\n\n\ndef wcs_to_hdr_dict(wcs_lsst):\n    md = wcs_lsst.getFitsMetadata()\n    return {k: md.getScalar(k) for k in md.names()}\n\n\n# ---- Euclid helpers ----\n\ndef sanitize_rms(rms, huge=1e10):\n    rms = rms.astype(np.float32, copy=False)\n    bad = (~np.isfinite(rms)) | (rms <= 0) | (rms > huge)\n    rms = rms.copy(); rms[bad] = np.nan\n    return rms\n\n\ndef robust_imshow(ax, img, title=\"\", p=(1, 99)):\n    if img is None:\n        ax.set_title(f\"{title} (missing)\"); ax.axis(\"off\"); return\n    lo, hi = np.nanpercentile(img, p)\n    ax.imshow(img, origin=\"lower\", vmin=lo, vmax=hi)\n    ax.set_title(title); ax.set_xticks([]); ax.set_yticks([])\n\n\ndef load_euclid_cutouts(ra, dec, size_arcsec, bands=bands_euclid,\n                        collection=\"euclid_DpdMerBksMosaic\", radius_arcsec=60):\n    coord = SkyCoord(ra=ra*u.deg, dec=dec*u.deg, frame=\"icrs\")\n    tab = Irsa.query_sia(pos=(coord, radius_arcsec*u.arcsec), collection=collection)\n    if not isinstance(tab, Table):\n        tab = tab.to_table()\n    out_img = {b: None for b in bands}\n    out_var = {b: None for b in bands}\n    wcs_out = {}\n\n    def get_row(band, subtype):\n        m = (tab[\"energy_bandpassname\"] == band) & (tab[\"dataproduct_subtype\"] == subtype)\n        rows = tab[m]\n        return rows[0] if len(rows) else None\n\n    for b in bands:\n        row_sci = get_row(b, \"science\")\n        if row_sci is None:\n            continue\n        with fsspec.open(row_sci[\"access_url\"], \"rb\") as f:\n            with fits.open(f, memmap=False) as hdul:\n                wcs0 = WCS(hdul[0].header)\n                cut = Cutout2D(hdul[0].data, coord, size_arcsec * u.arcsec, wcs=wcs0)\n                out_img[b] = np.array(cut.data, dtype=np.float32)\n                wcs_out[b] = cut.wcs\n        row_rms = get_row(b, \"noise\")\n        if row_rms is None:\n            continue\n        with fsspec.open(row_rms[\"access_url\"], \"rb\") as f:\n            with fits.open(f, memmap=False) as hdul:\n                wcsn = WCS(hdul[0].header)\n                cutn = Cutout2D(hdul[0].data, coord, size_arcsec * u.arcsec, wcs=wcsn)\n                rms = np.array(cutn.data, dtype=np.float32)\n        rms = sanitize_rms(rms, huge=1e10)\n        out_var[b] = rms * rms\n    return out_img, out_var, wcs_out\n\n\n# ---- Geometry & grouping helpers ----\n\ndef _bbox_sky_outline(bbox, wcs, n_pts=40):\n    \"\"\"Sample points along edges of a pixel bbox, project to RA/Dec.\"\"\"\n    xmin, ymin = bbox.getMin()\n    xmax, ymax = bbox.getMax()\n    pts = []\n    for x in np.linspace(xmin, xmax, n_pts): pts.append((x, ymin))\n    for y in np.linspace(ymin, ymax, n_pts): pts.append((xmax, y))\n    for x in np.linspace(xmax, xmin, n_pts): pts.append((x, ymax))\n    for y in np.linspace(ymax, ymin, n_pts): pts.append((xmin, y))\n    ra, dec = [], []\n    for x, y in pts:\n        sky = wcs.pixelToSky(geom.Point2D(x, y))\n        ra.append(sky.getRa().asDegrees())\n        dec.append(sky.getDec().asDegrees())\n    return ra, dec\n\n\ndef get_patch_rows(tract_info, patch_ids):\n    \"\"\"Group patch IDs into rows by their grid y-index.\n    Falls back to batches of ROW_BATCH if index lookup fails.\"\"\"\n    rows = {}\n    for pid in patch_ids:\n        try:\n            pinfo = tract_info[pid]\n            idx = pinfo.getIndex()\n            # 2D index (ix, iy) -> group by iy\n            if hasattr(idx, '__len__') and len(idx) == 2:\n                row_key = idx[1]\n            else:\n                row_key = pid // ROW_BATCH\n        except Exception:\n            row_key = pid // ROW_BATCH\n        rows.setdefault(row_key, []).append(pid)\n    return dict(sorted(rows.items()))\n\n\n# ---- Progress plot ----\n\ndef plot_progress():\n    \"\"\"Show patches with data (from butler) + downloaded tile centers.\"\"\"\n    skymap_obj = butler.get(\"skyMap\", skymap=SKYMAP)\n    tract_info = skymap_obj[TRACT]\n    tract_wcs = tract_info.getWcs()\n    patch_ids = get_patches_in_tract(butler, TRACT, band=\"r\")\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Tract outline\n    try:\n        verts = tract_info.getVertexList()\n        vra = [v.getRa().asDegrees() for v in verts] + [verts[0].getRa().asDegrees()]\n        vdec = [v.getDec().asDegrees() for v in verts] + [verts[0].getDec().asDegrees()]\n        ax.plot(vra, vdec, color=\"k\", linewidth=1.5, alpha=0.3, label=\"Tract boundary\")\n    except Exception:\n        pass\n\n    # Patches with data\n    for pid in patch_ids:\n        try:\n            pinfo = tract_info[pid]\n            bbox = geom.Box2D(pinfo.getOuterBBox())\n            ra, dec = _bbox_sky_outline(bbox, tract_wcs)\n            ax.plot(ra, dec, color=\"C3\", linewidth=0.7, alpha=0.5)\n        except Exception as e:\n            print(f\"  Could not plot patch {pid}: {e}\")\n\n    # Downloaded tile centers — on disk\n    ra_disk, dec_disk = [], []\n    for fn in sorted(glob.glob(f\"{OUT_RUBIN_ROOT}/**/tile_*.npz\", recursive=True)):\n        d = np.load(fn, allow_pickle=True)\n        ra_disk.append(float(d[\"ra_center\"]))\n        dec_disk.append(float(d[\"dec_center\"]))\n\n    # Downloaded tile centers — in archives\n    ra_arch, dec_arch = [], []\n    for arc in sorted(glob.glob(os.path.join(ARCHIVE_DIR, \"batch_*.tar.gz\"))):\n        with tarfile.open(arc, \"r:gz\") as tar:\n            for member in tar.getmembers():\n                if \"rubin_tiles\" in member.name and member.name.endswith(\".npz\"):\n                    f = tar.extractfile(member)\n                    d = np.load(io.BytesIO(f.read()), allow_pickle=True)\n                    ra_arch.append(float(d[\"ra_center\"]))\n                    dec_arch.append(float(d[\"dec_center\"]))\n\n    if ra_disk:\n        ax.scatter(ra_disk, dec_disk, s=3, color=\"C0\", alpha=0.7,\n                   label=f\"On disk ({len(ra_disk)})\")\n    if ra_arch:\n        ax.scatter(ra_arch, dec_arch, s=3, color=\"C1\", alpha=0.7,\n                   label=f\"Archived ({len(ra_arch)})\")\n\n    n_done = len(ra_disk) + len(ra_arch)\n    print(f\"{len(patch_ids)} patches with data, \"\n          f\"{n_done} tiles downloaded ({len(ra_disk)} disk, {len(ra_arch)} archived)\")\n\n    ax.set_xlabel(\"RA (deg)\")\n    ax.set_ylabel(\"Dec (deg)\")\n    ax.set_title(f\"Tract {TRACT}: {len(patch_ids)} patches with data\")\n    ax.legend(markerscale=3)\n    ax.invert_xaxis()\n    ax.set_aspect(\"equal\", adjustable=\"box\")\n    fig.tight_layout()\n    plt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3bbcd",
   "metadata": {},
   "outputs": [],
   "source": "plot_progress()"
  },
  {
   "cell_type": "markdown",
   "id": "62ece701",
   "metadata": {},
   "source": "# Tile-by-tile download\n\nFor each tile: save Rubin -> fetch Euclid -> plot progress -> compress -> pause for download.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3303002",
   "metadata": {},
   "outputs": [],
   "source": "# ---- Resume support ----\nprocessed = set()\nif os.path.exists(PROGRESS_FILE):\n    with open(PROGRESS_FILE) as f:\n        processed = {line.strip() for line in f if line.strip()}\n\npatch_ids = get_patches_in_tract(butler, TRACT, band=\"r\")\nprint(f\"Already archived: {len(processed)} tiles\")\nprint(f\"Tract {TRACT}: {len(patch_ids)} patches with data: {patch_ids}\")\n\ntile_num = len(processed)\n\nfor patch in patch_ids:\n    patch_label = f\"patch{int(patch):02d}\"\n    rubin_out_dir = os.path.join(OUT_RUBIN_ROOT, patch_label)\n    os.makedirs(rubin_out_dir, exist_ok=True)\n\n    try:\n        exps, wcs_full, bands_present = load_patch_exposures(\n            butler, tract=TRACT, patch=patch)\n    except Exception as e:\n        print(f\"Skipping {patch_label}: {e}\")\n        continue\n\n    patch_origin = exps[bands_present[0]].getXY0()\n    x0_patch, y0_patch = patch_origin.getX(), patch_origin.getY()\n    H, W = exps[bands_present[0]].image.array.shape\n\n    for y0 in range(0, H - TILE_SIZE + 1, STRIDE):\n        for x0 in range(0, W - TILE_SIZE + 1, STRIDE):\n            tile_id = f\"tile_x{x0:05d}_y{y0:05d}\"\n            progress_key = f\"{patch_label}/{tile_id}\"\n\n            if progress_key in processed:\n                continue\n\n            # ---- 1) Rubin tile ----\n            rubin_fn = os.path.join(rubin_out_dir, f\"{tile_id}.npz\")\n            gcx = x0_patch + x0 + (TILE_SIZE - 1) / 2.0\n            gcy = y0_patch + y0 + (TILE_SIZE - 1) / 2.0\n            sp = wcs_full.pixelToSky(gcx, gcy)\n            ra_c = sp.getRa().asDegrees()\n            dec_c = sp.getDec().asDegrees()\n            wcs_local = wcs_full.copyAtShiftedPixelOrigin(\n                geom.Extent2D(-(x0_patch + x0), -(y0_patch + y0)))\n\n            imgs, vars_, masks = [], [], []\n            for b in bands_present:\n                exp = exps[b]\n                imgs.append(exp.image.array[y0:y0+TILE_SIZE, x0:x0+TILE_SIZE].astype(np.float32))\n                vars_.append(exp.variance.array[y0:y0+TILE_SIZE, x0:x0+TILE_SIZE].astype(np.float32))\n                masks.append(exp.mask.array[y0:y0+TILE_SIZE, x0:x0+TILE_SIZE].astype(np.int32))\n\n            np.savez_compressed(rubin_fn,\n                img=np.stack(imgs), var=np.stack(vars_), mask=np.stack(masks),\n                wcs_hdr=wcs_to_hdr_dict(wcs_local),\n                x0=np.int32(x0), y0=np.int32(y0),\n                tile_id=np.bytes_(tile_id),\n                ra_center=np.float64(ra_c), dec_center=np.float64(dec_c),\n                tile_size=np.int32(TILE_SIZE), stride=np.int32(STRIDE),\n                bands=np.array(list(bands_present)))\n\n            # ---- 2) Euclid tile ----\n            euclid_fn = os.path.join(OUT_EUCLID_DIR, f\"{tile_id}_euclid.npz\")\n            if not os.path.exists(euclid_fn):\n                try:\n                    eu_imgs, eu_var, eu_wcss = load_euclid_cutouts(\n                        ra_c, dec_c, size_arcsec=EUCLID_SIZE_ARCSEC, bands=bands_euclid)\n                    save_dict = {\"ra_center\": ra_c, \"dec_center\": dec_c, \"tile_id\": tile_id}\n                    for b in bands_euclid:\n                        if eu_imgs[b] is not None:\n                            save_dict[f\"img_{b}\"] = eu_imgs[b]\n                            save_dict[f\"wcs_{b}\"] = eu_wcss[b].to_header_string()\n                        if eu_var[b] is not None:\n                            save_dict[f\"var_{b}\"] = eu_var[b]\n                    np.savez_compressed(euclid_fn, **save_dict)\n                    print(f\"  Euclid OK\")\n                except Exception as e:\n                    print(f\"  Euclid FAIL: {e}\")\n\n            # ---- 3) Plot progress ----\n            plot_progress()\n\n            # ---- 4) Compress ----\n            files = [rubin_fn]\n            if os.path.exists(euclid_fn):\n                files.append(euclid_fn)\n\n            archive_path = os.path.join(ARCHIVE_DIR, f\"tile_{tile_num:04d}.tar.gz\")\n            with tarfile.open(archive_path, \"w:gz\") as tar:\n                for fn in files:\n                    tar.add(fn, arcname=os.path.relpath(fn, DATA_ROOT))\n            for fn in files:\n                os.remove(fn)\n\n            with open(PROGRESS_FILE, \"a\") as f:\n                f.write(progress_key + \"\\n\")\n            processed.add(progress_key)\n            tile_num += 1\n\n            # ---- 5) Pause ----\n            print(f\"Tile {tile_num}: {progress_key} -> {os.path.basename(archive_path)}\")\n            input(\">>> Download the archive, delete it, then press Enter... \")\n\n    del exps\n\nprint(f\"\\nDone! {tile_num} tiles archived total.\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, numpy as np, matplotlib.pyplot as plt\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# pick one tile id for visualization\n",
    "tile_id_str = \"tile_x00000_y00000\"\n",
    "rubin_path  = os.path.join(OUT_RUBIN_ROOT,  \"patch00\", f\"{tile_id_str}.npz\")\n",
    "euclid_path = os.path.join(OUT_EUCLID_DIR, f\"{tile_id_str}_euclid.npz\")\n",
    "\n",
    "r_data = np.load(rubin_path)\n",
    "e_data = np.load(euclid_path)\n",
    "\n",
    "rubin_bands_full = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "nb_rubin = r_data['img'].shape[0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8)); axes = axes.flatten()\n",
    "\n",
    "# Rubin panels (only bands present)\n",
    "for i in range(nb_rubin):\n",
    "    band = rubin_bands_full[i] if i < len(rubin_bands_full) else f\"b{i}\"\n",
    "    robust_imshow(axes[i], r_data['img'][i], title=f\"Rubin {band}\")\n",
    "\n",
    "# Euclid panels\n",
    "for i, band in enumerate([\"VIS\", \"Y\", \"J\", \"H\"]):\n",
    "    ax = axes[i + 6]\n",
    "    img_key = f\"img_{band}\"\n",
    "    if img_key in e_data:\n",
    "        img = e_data[img_key]\n",
    "        robust_imshow(ax, img, title=f\"Euclid {band}\")\n",
    "    else:\n",
    "        ax.set_title(f\"Euclid {band} (Missing)\"); ax.axis('off')\n",
    "\n",
    "plt.suptitle(f\"Multi-band view: {tile_id_str}\n",
    "RA: {r_data['ra_center']:.4f}, Dec: {r_data['dec_center']:.4f}\", fontsize=16)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}