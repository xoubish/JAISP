{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b52326",
   "metadata": {},
   "source": [
    "# Tile Rubin tract 5063 (all patches) and fetch Euclid counterparts\n",
    "\n",
    "This mirrors `01_getdata_patch.ipynb` but loops over every patch in a tract. It tolerates missing bands/patches by skipping what's unavailable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334eb31c",
   "metadata": {},
   "outputs": [],
   "source": "import os, glob\nimport numpy as np\nfrom lsst.daf.butler import Butler\nimport lsst.geom as geom\n\n# ---- Config ----\nTRACT = 5063\nSKYMAP = \"lsst_cells_v1\"\nREPO = \"dp1\"\nCOLLECTION = \"LSSTComCam/DP1\"\nDATASETTYPE = \"deep_coadd\"\n\nOUT_RUBIN_ROOT = \"../data/rubin_tiles_tract5063\"\nos.makedirs(OUT_RUBIN_ROOT, exist_ok=True)\n\n# You can reorder / trim if you only need a subset\nbands_rubin = (\"u\",\"g\",\"r\",\"i\",\"z\",\"y\")\nTILE_SIZE = 512\nSTRIDE    = 256    # overlap\nMAX_TILES = None   # None => all tiles in that patch image\n\nbutler = Butler(REPO, collections=COLLECTION)\n\n\ndef get_patches_in_tract(butler, tract, band=\"r\", datasetType=DATASETTYPE, skymap=SKYMAP):\n    \"\"\"List patches that have *at least* the chosen band; safer than assuming all 100 exist.\"\"\"\n    refs = butler.query_datasets(\n        datasetType,\n        where=\"tract = tract AND band = band AND skymap = skymap\",\n        bind={\"tract\": tract, \"band\": band, \"skymap\": skymap},\n        with_dimension_records=True,\n    )\n    return sorted({ref.dataId[\"patch\"] for ref in refs})\n\n\ndef load_patch_exposures_by_id(butler, tract, patch, bands=bands_rubin, datasetType=DATASETTYPE, skymap=SKYMAP):\n    exps = {}\n    available = []\n    for b in bands:\n        dataId = {\"tract\": tract, \"patch\": patch, \"band\": b, \"skymap\": skymap}\n        try:\n            exps[b] = butler.get(datasetType, dataId=dataId)\n            available.append(b)\n        except Exception as e:\n            print(f\"  skipping band {b} for patch {patch}: {e}\")\n    if not available:\n        raise RuntimeError(f\"No bands found for patch {patch}\")\n    wcs_full = exps[available[0]].getWcs()\n    return exps, wcs_full, available\n\n\ndef wcs_to_hdr_dict_lsst(wcs_lsst):\n    md = wcs_lsst.getFitsMetadata()\n    return {k: md.getScalar(k) for k in md.names()}\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lsst.afw.geom as afwGeom\n",
    "from lsst.daf.base import PropertySet\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def wcs_from_hdr_dict(hdr_dict):\n",
    "    ps = PropertySet()\n",
    "    for k, v in hdr_dict.items():\n",
    "        ps.set(k, v)\n",
    "    return afwGeom.makeSkyWcs(ps)\n",
    "\n",
    "\n",
    "def tile_corners_from_npz(npz_path):\n",
    "    d = np.load(npz_path, allow_pickle=True)\n",
    "    wcs = wcs_from_hdr_dict(d[\"wcs_hdr\"].item())\n",
    "    tile_size = int(d[\"tile_size\"])\n",
    "    S = tile_size - 1\n",
    "    corners_pix = [(0,0),(S,0),(S,S),(0,S),(0,0)]\n",
    "    ra, dec = [], []\n",
    "    for x, y in corners_pix:\n",
    "        sp = wcs.pixelToSky(x, y)\n",
    "        ra.append(sp.getRa().asDegrees())\n",
    "        dec.append(sp.getDec().asDegrees())\n",
    "    return np.array(ra), np.array(dec)\n",
    "\n",
    "files = sorted(glob.glob(f\"{OUT_RUBIN_ROOT}/**/tile_*.npz\", recursive=True))\n",
    "print(\"Found\", len(files), \"tiles\")\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "for fn in files:\n",
    "    ra, dec = tile_corners_from_npz(fn)\n",
    "    plt.plot(ra, dec, linewidth=0.5, alpha=0.5)\n",
    "plt.xlabel(\"RA [deg]\")\n",
    "plt.ylabel(\"Dec [deg]\")\n",
    "plt.title(\"Rubin 512Ã—512 tile footprints (tract 5063)\")\n",
    "plt.gca().invert_xaxis(); plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ece701",
   "metadata": {},
   "source": "# Batch download: Rubin tiles + Euclid counterparts (quota-friendly)\n\nProcesses one tile at a time: **Rubin tile -> Euclid fetch -> next tile**.\nEvery `BATCH_SIZE` tiles, creates a `.tar.gz` archive and deletes the\noriginals to free disk space, then pauses for you to download the archive\nand delete it before continuing.\n\nProgress is tracked in `tile_progress.log` so re-running skips already-archived tiles.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3303002",
   "metadata": {},
   "outputs": [],
   "source": "import tarfile\nfrom astroquery.ipac.irsa import Irsa\nfrom astropy.coordinates import SkyCoord\nfrom astropy import units as u\nfrom astropy.table import Table\nfrom astropy.io import fits\nfrom astropy.nddata import Cutout2D\nfrom astropy.wcs import WCS\nimport fsspec\nimport os, glob, numpy as np\n\nfrom scipy.ndimage import maximum_filter, median_filter, zoom, gaussian_filter\nfrom scipy.optimize import linear_sum_assignment\nfrom scipy.stats import gaussian_kde\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Ellipse, Circle\nimport matplotlib.patches as mpatches\nfrom astropy.coordinates import match_coordinates_sky, search_around_sky\n\n\ndef sanitize_rms(rms, huge=1e10):\n    rms = rms.astype(np.float32, copy=False)\n    bad = (~np.isfinite(rms)) | (rms <= 0) | (rms > huge)\n    rms = rms.copy(); rms[bad] = np.nan\n    return rms\n\ndef robust_imshow(ax, img, title=\"\", p=(1, 99)):\n    if img is None:\n        ax.set_title(f\"{title} (missing)\"); ax.axis(\"off\"); return\n    lo, hi = np.nanpercentile(img, p)\n    ax.imshow(img, origin=\"lower\", vmin=lo, vmax=hi)\n    ax.set_title(title); ax.set_xticks([]); ax.set_yticks([])\n\ndef save_bundle(path, **kw):\n    np.savez_compressed(path, **{k: v for k, v in kw.items() if v is not None})\n    print(\"saved:\", path)\n\n\ndef load_euclid_cutouts(ra, dec, size_arcsec, bands=(\"VIS\",\"Y\",\"J\",\"H\"), collection=\"euclid_DpdMerBksMosaic\", radius_arcsec=60):\n    coord = SkyCoord(ra=ra*u.deg, dec=dec*u.deg, frame=\"icrs\")\n    tab = Irsa.query_sia(pos=(coord, radius_arcsec*u.arcsec), collection=collection)\n    if not isinstance(tab, Table):\n        tab = tab.to_table()\n    out_img = {b: None for b in bands}; out_var = {b: None for b in bands}; wcs_out = {}\n\n    def get_row(band, subtype):\n        m = (tab[\"energy_bandpassname\"] == band) & (tab[\"dataproduct_subtype\"] == subtype)\n        rows = tab[m]; return rows[0] if len(rows) else None\n\n    for b in bands:\n        row_sci = get_row(b, \"science\")\n        if row_sci is None:\n            continue\n        with fsspec.open(row_sci[\"access_url\"], \"rb\") as f:\n            with fits.open(f, memmap=False) as hdul:\n                wcs0 = WCS(hdul[0].header)\n                cut = Cutout2D(hdul[0].data, coord, size_arcsec * u.arcsec, wcs=wcs0)\n                out_img[b] = np.array(cut.data, dtype=np.float32)\n                wcs_out[b] = cut.wcs\n        row_rms = get_row(b, \"noise\")\n        if row_rms is None:\n            continue\n        with fsspec.open(row_rms[\"access_url\"], \"rb\") as f:\n            with fits.open(f, memmap=False) as hdul:\n                wcsn = WCS(hdul[0].header)\n                cutn = Cutout2D(hdul[0].data, coord, size_arcsec * u.arcsec, wcs=wcsn)\n                rms = np.array(cutn.data, dtype=np.float32)\n        rms = sanitize_rms(rms, huge=1e10)\n        out_var[b] = rms * rms\n    return out_img, out_var, wcs_out\n\n\n# ---- Config ----\nOUT_EUCLID_DIR = \"../data/euclid_tiles_tract5063\"\nbands_euclid = (\"VIS\", \"Y\", \"J\", \"H\")\nEUCLID_SIZE_ARCSEC = 105.0\n\nBATCH_SIZE = 10            # tiles per archive before pausing\nARCHIVE_DIR = \"../data/tile_archives\"\nPROGRESS_FILE = \"../data/tile_progress.log\"\nDATA_ROOT = os.path.abspath(\"../data\")\n\nos.makedirs(OUT_EUCLID_DIR, exist_ok=True)\nos.makedirs(ARCHIVE_DIR, exist_ok=True)\n\n# ---- Resume support ----\nprocessed = set()\nif os.path.exists(PROGRESS_FILE):\n    with open(PROGRESS_FILE) as f:\n        processed = {line.strip() for line in f if line.strip()}\nprint(f\"Resuming: {len(processed)} tiles already archived\")\n\n# ---- Main loop ----\npatch_ids = get_patches_in_tract(butler, TRACT, band=\"r\")\nprint(f\"Tract {TRACT}: {len(patch_ids)} patches with r-band\")\n\nbatch_files = []\nbatch_keys = []\nbatch_num = len(glob.glob(os.path.join(ARCHIVE_DIR, \"batch_*.tar.gz\")))\ntotal_new = 0\ntotal_skipped = 0\n\nfor patch in patch_ids:\n    patch_label = f\"patch{int(patch):02d}\"\n    rubin_out_dir = os.path.join(OUT_RUBIN_ROOT, patch_label)\n    os.makedirs(rubin_out_dir, exist_ok=True)\n\n    try:\n        exps, wcs_full, bands_present = load_patch_exposures_by_id(\n            butler, tract=TRACT, patch=patch)\n    except Exception as e:\n        print(f\"Skipping {patch_label}: {e}\")\n        continue\n\n    bands_tup = tuple(bands_present)\n    patch_origin = exps[bands_tup[0]].getXY0()\n    x0_patch, y0_patch = patch_origin.getX(), patch_origin.getY()\n    H, W = exps[bands_tup[0]].image.array.shape\n\n    for y0 in range(0, H - TILE_SIZE + 1, STRIDE):\n        for x0 in range(0, W - TILE_SIZE + 1, STRIDE):\n            tile_id = f\"tile_x{x0:05d}_y{y0:05d}\"\n            progress_key = f\"{patch_label}/{tile_id}\"\n\n            if progress_key in processed:\n                total_skipped += 1\n                continue\n\n            # ---- Save Rubin tile ----\n            rubin_fn = os.path.join(rubin_out_dir, f\"{tile_id}.npz\")\n            gcx = x0_patch + x0 + (TILE_SIZE - 1) / 2.0\n            gcy = y0_patch + y0 + (TILE_SIZE - 1) / 2.0\n            sp = wcs_full.pixelToSky(gcx, gcy)\n            ra_c = sp.getRa().asDegrees()\n            dec_c = sp.getDec().asDegrees()\n            wcs_local = wcs_full.copyAtShiftedPixelOrigin(\n                geom.Extent2D(-(x0_patch + x0), -(y0_patch + y0)))\n\n            imgs, vars_, masks = [], [], []\n            for b in bands_tup:\n                exp = exps[b]\n                imgs.append(exp.image.array[y0:y0+TILE_SIZE, x0:x0+TILE_SIZE].astype(np.float32))\n                vars_.append(exp.variance.array[y0:y0+TILE_SIZE, x0:x0+TILE_SIZE].astype(np.float32))\n                masks.append(exp.mask.array[y0:y0+TILE_SIZE, x0:x0+TILE_SIZE].astype(np.int32))\n\n            np.savez_compressed(rubin_fn,\n                img=np.stack(imgs), var=np.stack(vars_), mask=np.stack(masks),\n                wcs_hdr=wcs_to_hdr_dict_lsst(wcs_local),\n                x0=np.int32(x0), y0=np.int32(y0),\n                tile_id=np.bytes_(tile_id),\n                ra_center=np.float64(ra_c), dec_center=np.float64(dec_c),\n                tile_size=np.int32(TILE_SIZE), stride=np.int32(STRIDE),\n                bands=np.array(list(bands_tup)))\n            batch_files.append(rubin_fn)\n\n            # ---- Fetch & save Euclid tile ----\n            euclid_fn = os.path.join(OUT_EUCLID_DIR, f\"{tile_id}_euclid.npz\")\n            if not os.path.exists(euclid_fn):\n                try:\n                    eu_imgs, eu_var, eu_wcss = load_euclid_cutouts(\n                        ra_c, dec_c, size_arcsec=EUCLID_SIZE_ARCSEC, bands=bands_euclid)\n                    save_dict = {\"ra_center\": ra_c, \"dec_center\": dec_c, \"tile_id\": tile_id}\n                    for b in bands_euclid:\n                        if eu_imgs[b] is not None:\n                            save_dict[f\"img_{b}\"] = eu_imgs[b]\n                            save_dict[f\"wcs_{b}\"] = eu_wcss[b].to_header_string()\n                        if eu_var[b] is not None:\n                            save_dict[f\"var_{b}\"] = eu_var[b]\n                    np.savez_compressed(euclid_fn, **save_dict)\n                except Exception as e:\n                    print(f\"  Euclid failed for {progress_key}: {e}\")\n            if os.path.exists(euclid_fn):\n                batch_files.append(euclid_fn)\n\n            batch_keys.append(progress_key)\n            total_new += 1\n            print(f\"  {progress_key} ({total_new} new, {total_skipped} skipped)\")\n\n            # ---- Archive every BATCH_SIZE tiles ----\n            if len(batch_keys) >= BATCH_SIZE:\n                archive_path = os.path.join(ARCHIVE_DIR, f\"batch_{batch_num:04d}.tar.gz\")\n                with tarfile.open(archive_path, \"w:gz\") as tar:\n                    for fn in batch_files:\n                        tar.add(fn, arcname=os.path.relpath(fn, DATA_ROOT))\n                for fn in batch_files:\n                    os.remove(fn)\n                with open(PROGRESS_FILE, \"a\") as f:\n                    for key in batch_keys:\n                        f.write(key + \"\\n\")\n                processed.update(batch_keys)\n\n                print(f\"\\n{'='*60}\")\n                print(f\"  Batch {batch_num} -> {archive_path}\")\n                print(f\"  {len(batch_keys)} tiles archived, {total_new + total_skipped} total\")\n                print(f\"{'='*60}\")\n\n                batch_files = []\n                batch_keys = []\n                batch_num += 1\n                input(\">>> Download the archive, delete it, then press Enter to continue... \")\n\n    del exps  # free patch memory\n\n# ---- Final partial batch ----\nif batch_keys:\n    archive_path = os.path.join(ARCHIVE_DIR, f\"batch_{batch_num:04d}.tar.gz\")\n    with tarfile.open(archive_path, \"w:gz\") as tar:\n        for fn in batch_files:\n            tar.add(fn, arcname=os.path.relpath(fn, DATA_ROOT))\n    for fn in batch_files:\n        os.remove(fn)\n    with open(PROGRESS_FILE, \"a\") as f:\n        for key in batch_keys:\n            f.write(key + \"\\n\")\n    print(f\"\\nFinal batch {batch_num} -> {archive_path}\")\n    input(\">>> Download this last archive and delete it. Press Enter when done... \")\n\nprint(f\"\\nDone! {total_new} new tiles archived, {total_skipped} previously done.\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, numpy as np, matplotlib.pyplot as plt\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# pick one tile id for visualization\n",
    "tile_id_str = \"tile_x00000_y00000\"\n",
    "rubin_path  = os.path.join(OUT_RUBIN_ROOT,  \"patch00\", f\"{tile_id_str}.npz\")\n",
    "euclid_path = os.path.join(OUT_EUCLID_DIR, f\"{tile_id_str}_euclid.npz\")\n",
    "\n",
    "r_data = np.load(rubin_path)\n",
    "e_data = np.load(euclid_path)\n",
    "\n",
    "rubin_bands_full = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "nb_rubin = r_data['img'].shape[0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8)); axes = axes.flatten()\n",
    "\n",
    "# Rubin panels (only bands present)\n",
    "for i in range(nb_rubin):\n",
    "    band = rubin_bands_full[i] if i < len(rubin_bands_full) else f\"b{i}\"\n",
    "    robust_imshow(axes[i], r_data['img'][i], title=f\"Rubin {band}\")\n",
    "\n",
    "# Euclid panels\n",
    "for i, band in enumerate([\"VIS\", \"Y\", \"J\", \"H\"]):\n",
    "    ax = axes[i + 6]\n",
    "    img_key = f\"img_{band}\"\n",
    "    if img_key in e_data:\n",
    "        img = e_data[img_key]\n",
    "        robust_imshow(ax, img, title=f\"Euclid {band}\")\n",
    "    else:\n",
    "        ax.set_title(f\"Euclid {band} (Missing)\"); ax.axis('off')\n",
    "\n",
    "plt.suptitle(f\"Multi-band view: {tile_id_str}\n",
    "RA: {r_data['ra_center']:.4f}, Dec: {r_data['dec_center']:.4f}\", fontsize=16)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}