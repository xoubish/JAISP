{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6864bbe-5c1c-49e6-b4f9-2f38a7937845",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lsst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlsst\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdaf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbutler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Butler\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlsst\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgeom\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_one_deep_coadd_ref\u001b[39m(butler, ra, dec, band, datasetType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeep_coadd\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lsst'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from lsst.daf.butler import Butler\n",
    "import lsst.geom as geom\n",
    "\n",
    "def get_one_deep_coadd_ref(butler, ra, dec, band, datasetType=\"deep_coadd\"):\n",
    "    refs = list(butler.query_datasets(\n",
    "        datasetType,\n",
    "        where=\"band.name = band AND patch.region OVERLAPS POINT(ra, dec)\",\n",
    "        bind={\"band\": band, \"ra\": ra, \"dec\": dec},\n",
    "        with_dimension_records=True,\n",
    "        order_by=[\"patch.tract\"],\n",
    "    ))\n",
    "    if not refs:\n",
    "        raise RuntimeError(f\"No {datasetType} found for band={band} at ra,dec={ra},{dec}\")\n",
    "    return refs[0]\n",
    "\n",
    "def load_patch_exposures(\n",
    "    ra, dec,\n",
    "    bands=(\"u\",\"g\",\"r\",\"i\",\"z\",\"y\"),\n",
    "    repo=\"dp1\",\n",
    "    collection=\"LSSTComCam/DP1\",\n",
    "    datasetType=\"deep_coadd\",\n",
    "):\n",
    "    butler = Butler(repo, collections=collection)\n",
    "\n",
    "    ref0 = get_one_deep_coadd_ref(butler, ra, dec, bands[0], datasetType=datasetType)\n",
    "\n",
    "    # Convert DataCoordinate -> plain python dict safely\n",
    "    base_dataId = dict(ref0.dataId.mapping)\n",
    "\n",
    "\n",
    "    exps = {}\n",
    "    for b in bands:\n",
    "        dataId = dict(base_dataId)          # normal dict copy\n",
    "        dataId[\"band\"] = b                  # override just the band\n",
    "        exps[b] = butler.get(datasetType, dataId=dataId)\n",
    "\n",
    "    wcs_full = exps[bands[0]].getWcs()\n",
    "    return exps, wcs_full, base_dataId\n",
    "\n",
    "\n",
    "def tile_patch_and_save(\n",
    "    exps, wcs_full,\n",
    "    out_dir,\n",
    "    tile_size=512,\n",
    "    stride=256,\n",
    "    bands=(\"u\",\"g\",\"r\",\"i\",\"z\",\"y\"),\n",
    "    max_tiles=None,\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # assume all bands share same array shape\n",
    "    H, W = exps[bands[0]].image.array.shape\n",
    "    n_saved = 0\n",
    "\n",
    "    # iterate tile upper-left corners\n",
    "    for y0 in range(0, H - tile_size + 1, stride):\n",
    "        for x0 in range(0, W - tile_size + 1, stride):\n",
    "            bbox = geom.BoxI(geom.PointI(x0, y0), geom.ExtentI(tile_size, tile_size))\n",
    "            # cutout-local WCS: pixel origin shifted so (0,0) corresponds to (x0,y0) in full patch\n",
    "            wcs_local = wcs_full.copyAtShiftedPixelOrigin(geom.Extent2D(-x0, -y0))\n",
    "\n",
    "            imgs = []\n",
    "            vars_ = []\n",
    "            masks = []\n",
    "            for b in bands:\n",
    "                exp = exps[b]\n",
    "\n",
    "                # slice arrays directly (fast)\n",
    "                img = exp.image.array[y0:y0+tile_size, x0:x0+tile_size].astype(np.float32)\n",
    "                var = exp.variance.array[y0:y0+tile_size, x0:x0+tile_size].astype(np.float32)\n",
    "                msk = exp.mask.array[y0:y0+tile_size, x0:x0+tile_size].astype(np.int32)\n",
    "\n",
    "                imgs.append(img)\n",
    "                vars_.append(var)\n",
    "                masks.append(msk)\n",
    "\n",
    "            imgs = np.stack(imgs, axis=0)   # [B,H,W]\n",
    "            vars_ = np.stack(vars_, axis=0) # [B,H,W]\n",
    "            masks = np.stack(masks, axis=0) # [B,H,W]\n",
    "\n",
    "            # minimal WCS serialization: store CD + CRPIX + CRVAL from the local WCS\n",
    "            # (enough to reconstruct later; you can expand this if needed)\n",
    "            md = wcs_local.getFitsMetadata()\n",
    "            wcs_hdr = {k: md.getScalar(k) for k in md.names()}\n",
    "\n",
    "            fn = os.path.join(out_dir, f\"tile_x{x0:05d}_y{y0:05d}.npz\")\n",
    "            np.savez_compressed(\n",
    "                fn,\n",
    "                img=imgs,\n",
    "                var=vars_,\n",
    "                mask=masks,\n",
    "                wcs_hdr=wcs_hdr,\n",
    "                x0=np.int32(x0),\n",
    "                y0=np.int32(y0),\n",
    "            )\n",
    "            n_saved += 1\n",
    "            if (max_tiles is not None) and (n_saved >= max_tiles):\n",
    "                return n_saved\n",
    "    return n_saved\n",
    "\n",
    "# ---- Example: ECDFS center (rough) ----\n",
    "ra_ecdfs  = 53.16   # deg (rough)\n",
    "dec_ecdfs = -28.10    # deg (rough)\n",
    "\n",
    "bands = (\"u\",\"g\",\"r\",\"i\",\"z\",\"y\")  # start small; add u,z later\n",
    "exps, wcs_full, dataId0 = load_patch_exposures(\n",
    "    ra_ecdfs, dec_ecdfs, bands=bands,\n",
    "    repo=\"dp1\", collection=\"LSSTComCam/DP1\",\n",
    "    datasetType=\"deep_coadd\",\n",
    ")\n",
    "\n",
    "print(\"Using patch:\", dataId0)\n",
    "\n",
    "n = tile_patch_and_save(\n",
    "    exps, wcs_full,\n",
    "    out_dir=\"rubin_tiles_ecdfs\",\n",
    "    tile_size=512,\n",
    "    stride=256,\n",
    "    bands=bands,\n",
    "    max_tiles=200,   # just to start\n",
    ")\n",
    "print(\"Saved tiles:\", n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7abb5e-7f37-4057-acff-f5cf507ee3f7",
   "metadata": {},
   "source": [
    "# Adding Euclid and all other Rubin bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8034665-6156-4da9-967c-416eea9223a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No Rubin NPZ tiles found in rubin_tiles_ecdfs_gr_i",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 135\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone. Created Euclid tiles for:\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_done, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRubin tiles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# ---- run it ----\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m \u001b[43mmake_euclid_tiles_from_rubin_tiles\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrubin_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrubin_tiles_ecdfs_gr_i\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# update to your Rubin tile dir\u001b[39;49;00m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_vis_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuclid_tiles_VIS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_nisp_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuclid_tiles_NISP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize_arcsec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m102.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuclid_DpdMerBksMosaic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradius_arcsec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m, in \u001b[0;36mmake_euclid_tiles_from_rubin_tiles\u001b[0;34m(rubin_dir, out_vis_dir, out_nisp_dir, size_arcsec, bands_vis, bands_nisp, collection, radius_arcsec, max_tiles)\u001b[0m\n\u001b[1;32m     48\u001b[0m rubin_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(rubin_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rubin_files:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo Rubin NPZ tiles found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrubin_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rpath \u001b[38;5;129;01min\u001b[39;00m rubin_files[:max_tiles]:\n",
      "\u001b[0;31mValueError\u001b[0m: No Rubin NPZ tiles found in rubin_tiles_ecdfs_gr_i"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.io.fits import Header\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# ---- helpers ----\n",
    "def wcs_from_hdr_dict(wcs_hdr: dict) -> WCS:\n",
    "    hdr = Header()\n",
    "    for k, v in wcs_hdr.items():\n",
    "        if isinstance(v, np.generic):\n",
    "            v = v.item()\n",
    "        hdr[k] = v\n",
    "    return WCS(hdr)\n",
    "\n",
    "def wcs_to_hdr_dict(wcs: WCS) -> dict:\n",
    "    hdr = wcs.to_header(relax=True)\n",
    "    return {k: hdr[k] for k in hdr.keys()}\n",
    "\n",
    "def rubin_tile_center_radec(rubin_npz_path: str):\n",
    "    f = np.load(rubin_npz_path, allow_pickle=True)\n",
    "    img = f[\"img\"]  # [B,H,W]\n",
    "    H, W = img.shape[-2], img.shape[-1]\n",
    "    w = wcs_from_hdr_dict(f[\"wcs_hdr\"].item())\n",
    "    # center pixel in this *tile-local* WCS\n",
    "    cx, cy = (W - 1) / 2.0, (H - 1) / 2.0\n",
    "    ra, dec = w.all_pix2world(cx, cy, 0)\n",
    "    return float(ra), float(dec), (H, W)\n",
    "\n",
    "# ---- your Euclid cutout loader (assumed already defined in your notebook) ----\n",
    "# def load_euclid_cutouts(...): ...\n",
    "\n",
    "def make_euclid_tiles_from_rubin_tiles(\n",
    "    rubin_dir,\n",
    "    out_vis_dir=\"euclid_tiles_VIS\",\n",
    "    out_nisp_dir=\"euclid_tiles_NISP\",\n",
    "    size_arcsec=102.4,  # matches Rubin 512 * 0.2\"/pix\n",
    "    bands_vis=(\"VIS\",),\n",
    "    bands_nisp=(\"Y\",\"J\",\"H\"),\n",
    "    collection=\"euclid_DpdMerBksMosaic\",\n",
    "    radius_arcsec=120,          # search radius for SIA query\n",
    "    max_tiles=50,\n",
    "):\n",
    "    os.makedirs(out_vis_dir, exist_ok=True)\n",
    "    os.makedirs(out_nisp_dir, exist_ok=True)\n",
    "\n",
    "    rubin_files = sorted(glob.glob(os.path.join(rubin_dir, \"*.npz\")))\n",
    "    if not rubin_files:\n",
    "        raise ValueError(f\"No Rubin NPZ tiles found in {rubin_dir}\")\n",
    "\n",
    "    n_done = 0\n",
    "    for rpath in rubin_files[:max_tiles]:\n",
    "        tile_id = os.path.splitext(os.path.basename(rpath))[0]  # e.g. tile_x00000_y00000\n",
    "        ra, dec, _ = rubin_tile_center_radec(rpath)\n",
    "\n",
    "        # --- VIS cutout ---\n",
    "        out_vis, wcs_vis = load_euclid_cutouts(\n",
    "            ra, dec, size_arcsec,\n",
    "            bands=bands_vis,\n",
    "            collection=collection,\n",
    "            radius_arcsec=radius_arcsec,\n",
    "        )\n",
    "\n",
    "        if out_vis.get(\"VIS\") is None:\n",
    "            print(f\"[skip] {tile_id}: no VIS found at ra,dec={ra:.6f},{dec:.6f}\")\n",
    "            continue\n",
    "\n",
    "        vis_img = out_vis[\"VIS\"][None, ...].astype(np.float32)   # [1,H,W]\n",
    "        # If you don't have variance/mask from SIA products, store placeholders for now:\n",
    "        vis_var = np.ones_like(vis_img, dtype=np.float32)\n",
    "        vis_msk = np.zeros_like(vis_img, dtype=np.int32)\n",
    "\n",
    "        vis_hdr = wcs_to_hdr_dict(wcs_vis[\"VIS\"])\n",
    "\n",
    "        np.savez_compressed(\n",
    "            os.path.join(out_vis_dir, f\"{tile_id}.npz\"),\n",
    "            img=vis_img,\n",
    "            var=vis_var,\n",
    "            mask=vis_msk,\n",
    "            wcs_hdr=vis_hdr,\n",
    "            ra_center=np.float64(ra),\n",
    "            dec_center=np.float64(dec),\n",
    "            size_arcsec=np.float32(size_arcsec),\n",
    "            source_rubin=rpath,\n",
    "        )\n",
    "\n",
    "        # --- NISP cutouts (Y/J/H) ---\n",
    "        out_n, wcs_n = load_euclid_cutouts(\n",
    "            ra, dec, size_arcsec,\n",
    "            bands=bands_nisp,\n",
    "            collection=collection,\n",
    "            radius_arcsec=radius_arcsec,\n",
    "        )\n",
    "\n",
    "        n_imgs, n_hdrs = [], []\n",
    "        have_all = True\n",
    "        for b in bands_nisp:\n",
    "            if out_n.get(b) is None:\n",
    "                have_all = False\n",
    "                break\n",
    "            n_imgs.append(out_n[b].astype(np.float32))\n",
    "            n_hdrs.append(wcs_to_hdr_dict(wcs_n[b]))\n",
    "\n",
    "        if not have_all:\n",
    "            print(f\"[warn] {tile_id}: missing one of NISP {bands_nisp} at ra,dec={ra:.6f},{dec:.6f} (still saved VIS)\")\n",
    "            n_done += 1\n",
    "            continue\n",
    "\n",
    "        nisp_img = np.stack(n_imgs, axis=0)  # [3,H,W] but H,W may differ from VIS\n",
    "        nisp_var = np.ones_like(nisp_img, dtype=np.float32)\n",
    "        nisp_msk = np.zeros_like(nisp_img, dtype=np.int32)\n",
    "\n",
    "        # store per-band WCS headers as a list (object) so you can reconstruct each\n",
    "        np.savez_compressed(\n",
    "            os.path.join(out_nisp_dir, f\"{tile_id}.npz\"),\n",
    "            img=nisp_img,\n",
    "            var=nisp_var,\n",
    "            mask=nisp_msk,\n",
    "            wcs_hdr=n_hdrs,  # list of dicts (Y,J,H) in order\n",
    "            bands=np.array(list(bands_nisp)),\n",
    "            ra_center=np.float64(ra),\n",
    "            dec_center=np.float64(dec),\n",
    "            size_arcsec=np.float32(size_arcsec),\n",
    "            source_rubin=rpath,\n",
    "        )\n",
    "\n",
    "        n_done += 1\n",
    "        print(f\"[ok] {tile_id}: saved VIS + NISP at ra,dec={ra:.6f},{dec:.6f}\")\n",
    "\n",
    "    print(\"Done. Created Euclid tiles for:\", n_done, \"Rubin tiles\")\n",
    "\n",
    "\n",
    "# ---- run it ----\n",
    "make_euclid_tiles_from_rubin_tiles(\n",
    "    rubin_dir=\"../data/rubin_tiles_ecdfs\",  # update to your Rubin tile dir\n",
    "    out_vis_dir=\"../data/euclid_tiles_VIS\",\n",
    "    out_nisp_dir=\"../data/euclid_tiles_NISP\",\n",
    "    size_arcsec=102.4,\n",
    "    collection=\"euclid_DpdMerBksMosaic\",\n",
    "    radius_arcsec=120,\n",
    "    max_tiles=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96e34d8-ab85-47db-b1fd-39804e818676",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No NPZ tiles found. Check rubin_dir/euclid_dir paths.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 116\u001b[0m\n\u001b[1;32m    113\u001b[0m EUCLID_NISP_DIR\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclid_tiles_NISP\u001b[39m\u001b[38;5;124m\"\u001b[39m          \u001b[38;5;66;03m# contains NPZ with img[3,H,W], var, mask, wcs_hdr\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# 2) Build separate datasets so Rubin and Euclid are never tensor-stacked together by accident\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m ds_rubin \u001b[38;5;241m=\u001b[39m \u001b[43mSeparateSurveyTileDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrubin_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRUBIN_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43meuclid_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbands_rubin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbands_rubin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# all 6: u,g,r,i,z,y\u001b[39;49;00m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbands_euclid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbands_euclid\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m ds_vis \u001b[38;5;241m=\u001b[39m SeparateSurveyTileDataset(\n\u001b[1;32m    124\u001b[0m     rubin_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m     euclid_dir\u001b[38;5;241m=\u001b[39mEUCLID_VIS_DIR,\n\u001b[1;32m    126\u001b[0m     bands_rubin\u001b[38;5;241m=\u001b[39mbands_rubin,\n\u001b[1;32m    127\u001b[0m     bands_euclid\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVIS\u001b[39m\u001b[38;5;124m\"\u001b[39m]       \u001b[38;5;66;03m# VIS only\u001b[39;00m\n\u001b[1;32m    128\u001b[0m )\n\u001b[1;32m    130\u001b[0m ds_nisp \u001b[38;5;241m=\u001b[39m SeparateSurveyTileDataset(\n\u001b[1;32m    131\u001b[0m     rubin_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    132\u001b[0m     euclid_dir\u001b[38;5;241m=\u001b[39mEUCLID_NISP_DIR,\n\u001b[1;32m    133\u001b[0m     bands_rubin\u001b[38;5;241m=\u001b[39mbands_rubin,\n\u001b[1;32m    134\u001b[0m     bands_euclid\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# NISP only\u001b[39;00m\n\u001b[1;32m    135\u001b[0m )\n",
      "Cell \u001b[0;32mIn[1], line 51\u001b[0m, in \u001b[0;36mSeparateSurveyTileDataset.__init__\u001b[0;34m(self, rubin_dir, euclid_dir, bands_rubin, bands_euclid)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclid\u001b[39m\u001b[38;5;124m\"\u001b[39m, fn))\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo NPZ tiles found. Check rubin_dir/euclid_dir paths.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbands_rubin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(bands_rubin)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbands_euclid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(bands_euclid)\n",
      "\u001b[0;31mValueError\u001b[0m: No NPZ tiles found. Check rubin_dir/euclid_dir paths."
     ]
    }
   ],
   "source": [
    "# --- Rubin + Euclid tile reader (separate NPZ per survey/instrument), with safe batching ---\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from astropy.io.fits import Header\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# Bands (as requested)\n",
    "bands_rubin  = [\"u\",\"g\",\"r\",\"i\",\"z\",\"y\"]\n",
    "bands_euclid = [\"VIS\",\"Y\",\"J\",\"H\"]\n",
    "\n",
    "def wcs_from_hdr_dict(wcs_hdr: dict) -> WCS:\n",
    "    hdr = Header()\n",
    "    for k, v in wcs_hdr.items():\n",
    "        if isinstance(v, np.generic):\n",
    "            v = v.item()\n",
    "        hdr[k] = v\n",
    "    return WCS(hdr)\n",
    "\n",
    "# Rubin mask is a bitmask; set these later once you decide which planes to reject.\n",
    "BAD_BITS_RUBIN = 0\n",
    "\n",
    "def valid_from_bitmask(mask_int: torch.Tensor, bad_bits: int) -> torch.Tensor:\n",
    "    if bad_bits == 0:\n",
    "        return torch.ones_like(mask_int, dtype=torch.bool)\n",
    "    return (mask_int & bad_bits) == 0\n",
    "\n",
    "class SeparateSurveyTileDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Reads NPZ tiles saved like your Rubin code:\n",
    "      img: [B,H,W] float32\n",
    "      var: [B,H,W] float32\n",
    "      mask: [B,H,W] int32\n",
    "      wcs_hdr: dict (object)\n",
    "      x0,y0: optional\n",
    "\n",
    "    Works for multiple roots (Rubin + Euclid). Keeps files separate (no merging).\n",
    "    \"\"\"\n",
    "    def __init__(self, rubin_dir=None, euclid_dir=None,\n",
    "                 bands_rubin=bands_rubin, bands_euclid=bands_euclid):\n",
    "        self.items = []\n",
    "        if rubin_dir:\n",
    "            for fn in sorted(glob.glob(os.path.join(rubin_dir, \"*.npz\"))):\n",
    "                self.items.append((\"rubin\", fn))\n",
    "        if euclid_dir:\n",
    "            for fn in sorted(glob.glob(os.path.join(euclid_dir, \"*.npz\"))):\n",
    "                self.items.append((\"euclid\", fn))\n",
    "\n",
    "        if not self.items:\n",
    "            raise ValueError(\"No NPZ tiles found. Check rubin_dir/euclid_dir paths.\")\n",
    "\n",
    "        self.bands_rubin = list(bands_rubin)\n",
    "        self.bands_euclid = list(bands_euclid)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        survey, fn = self.items[idx]\n",
    "        f = np.load(fn, allow_pickle=True)\n",
    "\n",
    "        img = torch.from_numpy(f[\"img\"]).float()     # [B,H,W]\n",
    "        var = torch.from_numpy(f[\"var\"]).float()\n",
    "        msk = torch.from_numpy(f[\"mask\"]).int()      # Rubin: bitmask; Euclid: whatever you saved\n",
    "\n",
    "        wcs_hdr = f[\"wcs_hdr\"].item()\n",
    "        x0 = int(f[\"x0\"]) if \"x0\" in f else 0\n",
    "        y0 = int(f[\"y0\"]) if \"y0\" in f else 0\n",
    "\n",
    "        bands = self.bands_rubin if survey == \"rubin\" else self.bands_euclid\n",
    "\n",
    "        return {\n",
    "            \"survey\": survey,\n",
    "            \"bands\": bands,\n",
    "            \"img\": img,\n",
    "            \"var\": var,\n",
    "            \"mask\": msk,\n",
    "            \"wcs_hdr\": wcs_hdr,  # keep as dict; build WCS only when needed\n",
    "            \"x0\": x0,\n",
    "            \"y0\": y0,\n",
    "            \"path\": fn,\n",
    "        }\n",
    "\n",
    "def collate_tiles(batch):\n",
    "    # Split by survey so we never try to stack Rubin and Euclid together\n",
    "    out = {\"rubin\": None, \"euclid\": None}\n",
    "\n",
    "    for survey in (\"rubin\", \"euclid\"):\n",
    "        items = [b for b in batch if b[\"survey\"] == survey]\n",
    "        if not items:\n",
    "            continue\n",
    "\n",
    "        out[survey] = {\n",
    "            \"survey\": survey,\n",
    "            \"bands\": items[0][\"bands\"],                     # band list for this survey\n",
    "            \"img\": torch.stack([x[\"img\"] for x in items]),  # [N,B,H,W]\n",
    "            \"var\": torch.stack([x[\"var\"] for x in items]),\n",
    "            \"mask\": torch.stack([x[\"mask\"] for x in items]),\n",
    "            \"wcs_hdr\": [x[\"wcs_hdr\"] for x in items],       # list, not stacked\n",
    "            \"x0\": torch.tensor([x[\"x0\"] for x in items], dtype=torch.int32),\n",
    "            \"y0\": torch.tensor([x[\"y0\"] for x in items], dtype=torch.int32),\n",
    "            \"path\": [x[\"path\"] for x in items],\n",
    "        }\n",
    "\n",
    "    return out\n",
    "\n",
    "# ------------------ Exact usage: all bands, and use Euclid VIS WCS as the reference frame ------------------\n",
    "\n",
    "# 1) Set your tile directories (update these)\n",
    "RUBIN_DIR      = \"rubin_tiles_u_g_r_i_z_y\"      # contains NPZ with img[6,H,W], var, mask, wcs_hdr\n",
    "EUCLID_VIS_DIR = \"euclid_tiles_VIS\"            # contains NPZ with img[1,H,W], var, mask, wcs_hdr\n",
    "EUCLID_NISP_DIR= \"euclid_tiles_NISP\"          # contains NPZ with img[3,H,W], var, mask, wcs_hdr\n",
    "\n",
    "# 2) Build separate datasets so Rubin and Euclid are never tensor-stacked together by accident\n",
    "ds_rubin = SeparateSurveyTileDataset(\n",
    "    rubin_dir=RUBIN_DIR,\n",
    "    euclid_dir=None,\n",
    "    bands_rubin=bands_rubin,   # all 6: u,g,r,i,z,y\n",
    "    bands_euclid=bands_euclid\n",
    ")\n",
    "\n",
    "ds_vis = SeparateSurveyTileDataset(\n",
    "    rubin_dir=None,\n",
    "    euclid_dir=EUCLID_VIS_DIR,\n",
    "    bands_rubin=bands_rubin,\n",
    "    bands_euclid=[\"VIS\"]       # VIS only\n",
    ")\n",
    "\n",
    "ds_nisp = SeparateSurveyTileDataset(\n",
    "    rubin_dir=None,\n",
    "    euclid_dir=EUCLID_NISP_DIR,\n",
    "    bands_rubin=bands_rubin,\n",
    "    bands_euclid=[\"Y\",\"J\",\"H\"] # NISP only\n",
    ")\n",
    "\n",
    "# 3) Make three loaders (you will \"drive\" everything off VIS)\n",
    "dl_rubin = DataLoader(ds_rubin, batch_size=2, shuffle=True, num_workers=2, collate_fn=collate_tiles)\n",
    "dl_vis   = DataLoader(ds_vis,   batch_size=2, shuffle=True, num_workers=2, collate_fn=collate_tiles)\n",
    "dl_nisp  = DataLoader(ds_nisp,  batch_size=2, shuffle=True, num_workers=2, collate_fn=collate_tiles)\n",
    "\n",
    "# 4) Pull one batch from each (you can zip these once filenames/tile-ids are aligned)\n",
    "b_rubin = next(iter(dl_rubin))[\"rubin\"]     # dict with img/var/mask/wcs_hdr list\n",
    "b_vis   = next(iter(dl_vis))[\"euclid\"]     # VIS batch stored under \"euclid\"\n",
    "b_nisp  = next(iter(dl_nisp))[\"euclid\"]    # NISP batch stored under \"euclid\"\n",
    "\n",
    "print(\"Rubin:\", b_rubin[\"img\"].shape, b_rubin[\"bands\"])\n",
    "print(\"Euclid VIS:\", b_vis[\"img\"].shape, b_vis[\"bands\"])\n",
    "print(\"Euclid NISP:\", b_nisp[\"img\"].shape, b_nisp[\"bands\"])\n",
    "\n",
    "# 5) Reference WCS = Euclid VIS WCS for each sample in the VIS batch\n",
    "# Build WCS objects only when needed (cheap enough for batch_size~2; cache later if needed)\n",
    "vis_wcs_list = [wcs_from_hdr_dict(h) for h in b_vis[\"wcs_hdr\"]]\n",
    "\n",
    "# 6) Example: mapping Rubin/NISP pixels -> sky -> VIS pixel coordinates (for matching/alignment)\n",
    "# (This is the correct way to \"match everything to VIS\" without resampling.)\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "def pix_to_sky(wcs: WCS, x: np.ndarray, y: np.ndarray) -> SkyCoord:\n",
    "    ra, dec = wcs.all_pix2world(x, y, 0)\n",
    "    return SkyCoord(ra*u.deg, dec*u.deg)\n",
    "\n",
    "def sky_to_pix(wcs: WCS, sc: SkyCoord):\n",
    "    x, y = wcs.all_world2pix(sc.ra.deg, sc.dec.deg, 0)\n",
    "    return x, y\n",
    "\n",
    "# Choose sample 0 in the VIS batch\n",
    "wcs_vis  = vis_wcs_list[0]\n",
    "wcs_rub  = wcs_from_hdr_dict(b_rubin[\"wcs_hdr\"][0])\n",
    "wcs_nisp = wcs_from_hdr_dict(b_nisp[\"wcs_hdr\"][0])\n",
    "\n",
    "# Example pixel (center of the Rubin tile) -> sky -> VIS pixel\n",
    "Hr, Wr = b_rubin[\"img\"].shape[-2:]\n",
    "x_r, y_r = np.array([Wr/2.0]), np.array([Hr/2.0])\n",
    "sc = pix_to_sky(wcs_rub, x_r, y_r)\n",
    "x_v, y_v = sky_to_pix(wcs_vis, sc)\n",
    "\n",
    "print(\"Rubin center maps to VIS pixel:\", float(x_v[0]), float(y_v[0]))\n",
    "\n",
    "# Same for NISP center -> VIS pixel\n",
    "Hn, Wn = b_nisp[\"img\"].shape[-2:]\n",
    "x_n, y_n = np.array([Wn/2.0]), np.array([Hn/2.0])\n",
    "sc2 = pix_to_sky(wcs_nisp, x_n, y_n)\n",
    "x_v2, y_v2 = sky_to_pix(wcs_vis, sc2)\n",
    "\n",
    "print(\"NISP center maps to VIS pixel:\", float(x_v2[0]), float(y_v2[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d086d7e-58e1-47bc-896e-5849fb3c4fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
